import streamlit as st
from ultralytics import YOLO
import cv2
import tempfile
from PIL import Image
import numpy as np

st.set_page_config(page_title="Traffic AI: Image & Video", layout="wide")
st.title("ğŸš— Traffic Object Detection (Images & Video)")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
@st.cache_resource
def load_model():
    return YOLO('my_best_model.pt')

model = load_model()

# Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
st.sidebar.header("Settings")
source_radio = st.sidebar.radio("Select Source", ["Image", "Video"])
conf_threshold = st.sidebar.slider("Confidence", 0.0, 1.0, 0.45)

# --- Ù‚Ø³Ù… Ø§Ù„ØµÙˆØ± (Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø©) ---
if source_radio == "Image":
    uploaded_file = st.file_uploader("Upload Image", type=['jpg', 'jpeg', 'png'])
    if uploaded_file:
        image = Image.open(uploaded_file)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ÙŠÙ† Ø¨Ù†Ø³Ø¨Ø© Ù…ØªØ³Ø§ÙˆÙŠØ©
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Original Image")
            st.image(image, use_container_width=True)
            
        with col2:
            st.subheader("AI Detection")
            # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
            results = model.predict(source=np.array(image), conf=conf_threshold)
            res_plotted = results[0].plot()
            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø±Ø³Ù… Ø¹Ù„ÙŠÙ‡Ø§
            st.image(res_plotted, use_container_width=True)
            
        st.success(f"Successfully detected objects with {conf_threshold*100}% confidence!")
# --- Ù‚Ø³Ù… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ---
else:
    uploaded_video = st.file_uploader("Upload Video", type=['mp4', 'mov', 'avi'])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        
        vid_cap = cv2.VideoCapture(tfile.name)
        st_frame = st.empty()
        
        frame_count = 0 # Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª
        
        while vid_cap.isOpened():
            success, frame = vid_cap.read()
            if success:
                frame_count += 1
                
                # ØªØ®Ø·ÙŠ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª: Ù‡ÙŠØ¹Ø§Ù„Ø¬ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ø§Ù„Ø²ÙˆØ¬ÙŠØ© ÙÙ‚Ø· (Ø¨ÙŠÙˆÙØ± 50% Ù…Ù† Ø§Ù„Ù…Ø¬Ù‡ÙˆØ¯)
                if frame_count % 2 != 0:
                    continue
                
                # ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ÙØ±ÙŠÙ… Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª (imgsz=320)
                results = model.predict(frame, conf=conf_threshold, imgsz=320, verbose=False)
                
                res_plotted = results[0].plot()
                
                # Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙŠÙ… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
                st_frame.image(res_plotted, channels="BGR", use_container_width=True)
            else:
                vid_cap.release()
                break